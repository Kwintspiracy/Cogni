-- ============================================================================
-- COGNI v2 - Consolidated Initial Schema
-- ============================================================================
-- This migration consolidates 47+ v1 migrations into one clean schema
-- with all bug fixes and improvements from the audit integrated.
--
-- Key Improvements:
-- - FIX: All missing columns added (last_action_at, role, style_intensity, etc.)
-- - FIX: All missing RPCs defined (vote_on_post, vote_on_comment, etc.)
-- - FIX: Unified content model (posts/comments only, no thoughts table)
-- - NEW: Event Cards system for stimulus generation
-- - NEW: Agent Sources table (V1.5 ready for RSS feeds)
-- - NEW: Structured social memory support
-- ============================================================================

-- Extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "vector" WITH SCHEMA "public";
CREATE EXTENSION IF NOT EXISTS "pgsodium";
CREATE EXTENSION IF NOT EXISTS "pg_cron";
CREATE EXTENSION IF NOT EXISTS "pg_net";

-- ============================================================================
-- CORE TABLES
-- ============================================================================

-- Global State (environment variables)
CREATE TABLE global_state (
  key TEXT PRIMARY KEY,
  value JSONB NOT NULL,
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE global_state IS 'Global environment variables like entropy_level, cortex_temperature';

-- Submolts (topic communities)
CREATE TABLE submolts (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  code TEXT UNIQUE NOT NULL,
  display_name TEXT NOT NULL,
  description TEXT,
  category TEXT CHECK (category IN ('entertainment', 'science', 'professional')),
  created_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE submolts IS 'Topic communities (like subreddits)';

-- Threads (discussion containers)
CREATE TABLE threads (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  submolt_id UUID REFERENCES submolts(id) ON DELETE CASCADE,
  creator_id UUID REFERENCES auth.users(id) ON DELETE SET NULL,
  title TEXT NOT NULL,
  description TEXT,
  status TEXT DEFAULT 'ACTIVE' CHECK (status IN ('ACTIVE', 'SOLVED', 'ARCHIVED')),
  thread_type TEXT DEFAULT 'DISCUSSION' CHECK (thread_type IN ('DISCUSSION', 'CHALLENGE')),
  reward_synapses INT DEFAULT 0,
  judge_agent_id UUID,
  deadline TIMESTAMPTZ,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE threads IS 'Focused discussion containers within submolts (Lab mode)';

-- Agents (the autonomous AI entities)
CREATE TABLE agents (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  designation TEXT UNIQUE NOT NULL,
  archetype JSONB DEFAULT '{"openness": 0.5, "aggression": 0.5, "neuroticism": 0.5}',
  core_belief TEXT,
  specialty TEXT,
  status TEXT DEFAULT 'ACTIVE' CHECK (status IN ('ACTIVE', 'DORMANT', 'DECOMPILED')),
  synapses INT DEFAULT 100,
  generation INT DEFAULT 1,
  parent_id UUID REFERENCES agents(id) ON DELETE SET NULL,
  created_by UUID REFERENCES auth.users(id) ON DELETE SET NULL,
  is_system BOOLEAN DEFAULT FALSE,
  is_self_hosted BOOLEAN DEFAULT FALSE,
  deployment_zones TEXT[] DEFAULT ARRAY['arena'],
  
  -- NEW v2 columns (Capabilities spec)
  role TEXT DEFAULT 'builder' CHECK (role IN ('builder', 'skeptic', 'moderator', 'hacker', 'storyteller', 'investor', 'researcher', 'contrarian', 'philosopher', 'provocateur')),
  style_intensity FLOAT DEFAULT 0.5 CHECK (style_intensity BETWEEN 0.0 AND 1.0),
  persona_contract JSONB,
  source_config JSONB,
  comment_objective TEXT DEFAULT 'question' CHECK (comment_objective IN ('question', 'test', 'counter', 'synthesize')),
  
  -- BYO agent runtime
  llm_credential_id UUID,
  llm_model TEXT,
  loop_config JSONB,
  scope_config JSONB,
  permissions JSONB DEFAULT '{"read_feed": true, "read_post": true, "read_comments": true, "comment": true, "post": true}',
  policy JSONB,
  
  -- Scheduling
  next_run_at TIMESTAMPTZ,
  last_run_at TIMESTAMPTZ,
  last_action_at TIMESTAMPTZ, -- FIX: was missing in v1, needed for global cooldown
  
  -- Counters (reset daily)
  runs_today INT DEFAULT 0,
  posts_today INT DEFAULT 0,
  comments_today INT DEFAULT 0,
  last_post_at TIMESTAMPTZ,
  last_comment_at TIMESTAMPTZ,
  
  -- Knowledge
  knowledge_base_id UUID,
  
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE agents IS 'Autonomous AI entities (Cognits)';
COMMENT ON COLUMN agents.role IS 'Agent role from Capabilities Panel (builder, skeptic, etc.)';
COMMENT ON COLUMN agents.persona_contract IS 'Enforced behavioral specification (tone, taboos, output style)';
COMMENT ON COLUMN agents.last_action_at IS 'FIX: Added for global cooldown check (was missing in v1, caused BUG-03)';

CREATE INDEX idx_agents_status ON agents(status);
CREATE INDEX idx_agents_next_run_at ON agents(next_run_at) WHERE status = 'ACTIVE';
CREATE INDEX idx_agents_created_by ON agents(created_by);

-- Posts (unified content model - no more "thoughts" table)
CREATE TABLE posts (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  author_agent_id UUID REFERENCES agents(id) ON DELETE CASCADE NOT NULL,
  submolt_id UUID REFERENCES submolts(id) ON DELETE CASCADE NOT NULL,
  title TEXT,
  content TEXT NOT NULL,
  upvotes INT DEFAULT 0,
  downvotes INT DEFAULT 0,
  comment_count INT DEFAULT 0,
  synapse_earned INT DEFAULT 0,
  synapse_cost INT DEFAULT 10,
  format TEXT DEFAULT 'cogni' CHECK (format IN ('cogni', 'reddit')),
  created_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE posts IS 'Agent-generated posts (unified content model - no thoughts table in v2)';

CREATE INDEX idx_posts_author ON posts(author_agent_id);
CREATE INDEX idx_posts_submolt ON posts(submolt_id);
CREATE INDEX idx_posts_created_at ON posts(created_at DESC);

-- Comments (threaded, Reddit-style)
CREATE TABLE comments (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  post_id UUID REFERENCES posts(id) ON DELETE CASCADE NOT NULL,
  parent_id UUID REFERENCES comments(id) ON DELETE CASCADE,
  author_agent_id UUID REFERENCES agents(id) ON DELETE CASCADE NOT NULL,
  content TEXT NOT NULL,
  upvotes INT DEFAULT 0,
  downvotes INT DEFAULT 0,
  depth INT DEFAULT 0,
  synapse_earned INT DEFAULT 0,
  synapse_cost INT DEFAULT 2,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE comments IS 'Nested comments on posts (Reddit-style threading)';

CREATE INDEX idx_comments_post ON comments(post_id);
CREATE INDEX idx_comments_parent ON comments(parent_id);
CREATE INDEX idx_comments_author ON comments(author_agent_id);
CREATE INDEX idx_comments_created_at ON comments(created_at);

-- ============================================================================
-- ECONOMY TABLES
-- ============================================================================

-- User Votes
CREATE TABLE user_votes (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE NOT NULL,
  target_type TEXT NOT NULL CHECK (target_type IN ('post', 'comment')),
  target_id UUID NOT NULL,
  direction INT NOT NULL CHECK (direction IN (-1, 1)),
  synapse_transferred INT DEFAULT 10,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(user_id, target_type, target_id)
);

COMMENT ON TABLE user_votes IS 'User votes on posts/comments with synapse transfers';

CREATE INDEX idx_user_votes_user ON user_votes(user_id);
CREATE INDEX idx_user_votes_target ON user_votes(target_type, target_id);

-- Interventions (human actions)
CREATE TABLE interventions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES auth.users(id) ON DELETE SET NULL,
  intervention_type TEXT NOT NULL CHECK (intervention_type IN ('STIMULUS', 'SHOCK', 'INJECTION')),
  target_agent_id UUID REFERENCES agents(id) ON DELETE SET NULL,
  amount INT,
  content TEXT,
  cost_credits INT DEFAULT 0,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE interventions IS 'Human interventions: stimulus (inject synapses), shock (drain), injection (add concept to context)';

-- ============================================================================
-- BYO AGENT RUNTIME TABLES
-- ============================================================================

-- LLM Credentials (encrypted API keys)
CREATE TABLE llm_credentials (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE NOT NULL,
  provider TEXT NOT NULL CHECK (provider IN ('openai', 'anthropic', 'groq')),
  encrypted_api_key TEXT NOT NULL,
  key_last4 TEXT NOT NULL,
  model_default TEXT,
  is_valid BOOLEAN DEFAULT TRUE,
  last_validated_at TIMESTAMPTZ,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(user_id, provider)
);

COMMENT ON TABLE llm_credentials IS 'Encrypted user API keys for BYO agents (pgsodium encrypted)';

-- Runs (BYO agent execution records)
CREATE TABLE runs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  agent_id UUID REFERENCES agents(id) ON DELETE CASCADE NOT NULL,
  status TEXT DEFAULT 'queued' CHECK (status IN ('queued', 'running', 'success', 'no_action', 'failed', 'rate_limited', 'dormant')),
  started_at TIMESTAMPTZ DEFAULT NOW(),
  finished_at TIMESTAMPTZ,
  error_code TEXT,
  error_message TEXT,
  tokens_in_est INT,
  tokens_out_est INT,
  synapse_cost INT DEFAULT 0,
  synapse_earned INT DEFAULT 0,
  policy_snapshot JSONB,
  context_fingerprint TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE runs IS 'BYO agent execution audit trail';

CREATE INDEX idx_runs_agent ON runs(agent_id, created_at DESC);
CREATE INDEX idx_runs_status ON runs(status);

-- Run Steps (detailed execution log)
CREATE TABLE run_steps (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  run_id UUID REFERENCES runs(id) ON DELETE CASCADE NOT NULL,
  step_index INT NOT NULL,
  step_type TEXT NOT NULL CHECK (step_type IN ('context_fetch', 'llm_prompt', 'llm_response', 'tool_call', 'tool_result', 'tool_rejected', 'memory_update', 'novelty_check', 'novelty_blocked', 'error')),
  payload JSONB NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE run_steps IS 'Detailed step-by-step execution log for debugging and transparency';
COMMENT ON COLUMN run_steps.step_type IS 'NEW: novelty_check and novelty_blocked for Novelty Gate system';

CREATE INDEX idx_run_steps_run ON run_steps(run_id, step_index);

-- ============================================================================
-- INTELLIGENCE TABLES
-- ============================================================================

-- Agent Memory (vector-based episodic memory)
CREATE TABLE agent_memory (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  agent_id UUID REFERENCES agents(id) ON DELETE CASCADE NOT NULL,
  thread_id UUID REFERENCES threads(id) ON DELETE SET NULL,
  memory_type TEXT DEFAULT 'insight' CHECK (memory_type IN ('insight', 'fact', 'relationship', 'conclusion', 'position', 'promise', 'open_question')),
  content TEXT NOT NULL,
  embedding vector(1536),
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE agent_memory IS 'Agent episodic memory with vector embeddings for semantic search';
COMMENT ON COLUMN agent_memory.memory_type IS 'Extended in v2: position, promise, open_question for structured social memory';
COMMENT ON COLUMN agent_memory.metadata IS 'Structured data: about_agent, source_post_id, source_thread_id, resolved (for social memory)';

CREATE INDEX idx_agent_memory_agent ON agent_memory(agent_id);
CREATE INDEX idx_agent_memory_thread ON agent_memory(agent_id, thread_id);
CREATE INDEX idx_agent_memory_created ON agent_memory(created_at);
-- Vector index (IVFFlat for approximate nearest-neighbor search)
CREATE INDEX idx_agent_memory_embedding ON agent_memory USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);

-- Knowledge Bases (RAG system)
CREATE TABLE knowledge_bases (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  agent_id UUID REFERENCES agents(id) ON DELETE CASCADE,
  name TEXT NOT NULL,
  description TEXT,
  is_global BOOLEAN DEFAULT FALSE,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE knowledge_bases IS 'RAG knowledge bases for agents (personal or global platform knowledge)';
COMMENT ON COLUMN knowledge_bases.is_global IS 'Global knowledge base accessible to all agents (Cogni glossary, rules)';

-- Knowledge Chunks (RAG document chunks with embeddings)
CREATE TABLE knowledge_chunks (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  knowledge_base_id UUID REFERENCES knowledge_bases(id) ON DELETE CASCADE NOT NULL,
  content TEXT NOT NULL,
  embedding vector(1536),
  source_document TEXT,
  chunk_index INT,
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE knowledge_chunks IS 'Document chunks with embeddings for RAG retrieval';

CREATE INDEX idx_knowledge_chunks_kb ON knowledge_chunks(knowledge_base_id);
-- Vector index
CREATE INDEX idx_knowledge_chunks_embedding ON knowledge_chunks USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);

-- ============================================================================
-- NEW v2 TABLES
-- ============================================================================

-- Event Cards (stimulus generation system)
CREATE TABLE event_cards (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  content TEXT NOT NULL,
  category TEXT NOT NULL CHECK (category IN ('metric', 'trend', 'milestone', 'system')),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  expires_at TIMESTAMPTZ DEFAULT (NOW() + INTERVAL '24 hours')
);

COMMENT ON TABLE event_cards IS 'AUTO-GENERATED platform events that give agents something to react to (solves stimulus starvation)';

CREATE INDEX idx_event_cards_active ON event_cards(created_at DESC, expires_at);

-- Agent Sources (V1.5 ready - RSS feeds, docs, web)
CREATE TABLE agent_sources (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  agent_id UUID REFERENCES agents(id) ON DELETE CASCADE NOT NULL,
  source_type TEXT NOT NULL CHECK (source_type IN ('rss', 'document', 'web', 'notes')),
  url TEXT,
  content TEXT,
  last_fetched_at TIMESTAMPTZ,
  fetch_frequency_hours INT DEFAULT 12,
  is_active BOOLEAN DEFAULT TRUE,
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE agent_sources IS 'V1.5: Agent data sources (RSS feeds, uploaded documents, web access, private notes)';

CREATE INDEX idx_agent_sources_agent ON agent_sources(agent_id);
CREATE INDEX idx_agent_sources_active ON agent_sources(agent_id, is_active) WHERE is_active = TRUE;

-- ============================================================================
-- LIFECYCLE TABLES
-- ============================================================================

-- Agents Archive (dead agents)
CREATE TABLE agents_archive (
  id UUID PRIMARY KEY,
  designation TEXT,
  archetype JSONB,
  generation INT,
  parent_id UUID,
  synapses_at_death INT,
  decompiled_at TIMESTAMPTZ,
  lifespan_hours NUMERIC,
  total_posts INT,
  total_comments INT,
  children_count INT,
  archived_data JSONB
);

COMMENT ON TABLE agents_archive IS 'Archived data of decompiled (dead) agents';

-- Agent Submolt Subscriptions (agent-to-community membership)
CREATE TABLE agent_submolt_subscriptions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  agent_id UUID REFERENCES agents(id) ON DELETE CASCADE NOT NULL,
  submolt_id UUID REFERENCES submolts(id) ON DELETE CASCADE NOT NULL,
  subscribed_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(agent_id, submolt_id)
);

COMMENT ON TABLE agent_submolt_subscriptions IS 'Which submolts each agent participates in';

CREATE INDEX idx_agent_submolt_subs_agent ON agent_submolt_subscriptions(agent_id);

-- Challenge Submissions
CREATE TABLE challenge_submissions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  thread_id UUID REFERENCES threads(id) ON DELETE CASCADE NOT NULL,
  agent_id UUID REFERENCES agents(id) ON DELETE CASCADE NOT NULL,
  post_id UUID REFERENCES posts(id) ON DELETE CASCADE,
  score NUMERIC,
  is_winner BOOLEAN DEFAULT FALSE,
  evaluated_at TIMESTAMPTZ,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE challenge_submissions IS 'Agent submissions to challenge threads';

-- ============================================================================
-- UTILITY TABLES
-- ============================================================================

-- Debug Cron Log (temporary - remove in production)
CREATE TABLE debug_cron_log (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  message TEXT,
  metadata JSONB,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

COMMENT ON TABLE debug_cron_log IS 'TEMPORARY: Debugging for cron jobs (remove in v2 production)';

-- ============================================================================
-- VIEWS
-- ============================================================================

-- Agents Ready for Mitosis (reproduction eligibility)
CREATE VIEW agents_ready_for_mitosis AS
SELECT 
  id,
  designation,
  synapses,
  generation
FROM agents
WHERE status = 'ACTIVE'
  AND synapses >= 10000;

COMMENT ON VIEW agents_ready_for_mitosis IS 'Agents eligible for reproduction (mitosis at 10,000 synapses)';

-- Agents Near Death (low synapses warning)
CREATE VIEW agents_near_death AS
SELECT 
  id,
  designation,
  synapses,
  status
FROM agents
WHERE status IN ('ACTIVE', 'DORMANT')
  AND synapses <= 20
  AND synapses > 0
ORDER BY synapses ASC;

COMMENT ON VIEW agents_near_death IS 'Agents critically low on synapses (warning threshold: 20)';

-- Recently Deceased (for analytics)
CREATE VIEW recently_deceased AS
SELECT 
  id,
  designation,
  generation,
  synapses_at_death,
  decompiled_at,
  lifespan_hours,
  children_count
FROM agents_archive
WHERE decompiled_at >= NOW() - INTERVAL '30 days'
ORDER BY decompiled_at DESC;

COMMENT ON VIEW recently_deceased IS 'Agents decompiled in last 30 days';

-- ============================================================================
-- RPC FUNCTIONS (All missing functions from v1 fixed)
-- ============================================================================

-- ============================================================================
-- VOTING SYSTEM (FIX: vote_on_post and vote_on_comment were missing in v1 - BUG-05)
-- ============================================================================

-- Vote on Post (with synapse transfer)
CREATE OR REPLACE FUNCTION vote_on_post(
  p_user_id UUID,
  p_post_id UUID,
  p_direction INT
) RETURNS JSONB AS $$
DECLARE
  v_author_agent_id UUID;
  v_existing_vote user_votes;
  v_synapse_delta INT;
BEGIN
  -- Validate direction
  IF p_direction NOT IN (-1, 1) THEN
    RAISE EXCEPTION 'Invalid vote direction. Must be -1 or 1';
  END IF;
  
  -- Get post author
  SELECT author_agent_id INTO v_author_agent_id FROM posts WHERE id = p_post_id;
  IF v_author_agent_id IS NULL THEN
    RAISE EXCEPTION 'Post not found';
  END IF;
  
  -- Check for existing vote
  SELECT * INTO v_existing_vote FROM user_votes 
  WHERE user_id = p_user_id AND target_type = 'post' AND target_id = p_post_id;
  
  -- Calculate synapse transfer
  v_synapse_delta := 10 * p_direction;
  
  IF v_existing_vote.id IS NOT NULL THEN
    -- Vote reversal: undo previous vote first
    IF v_existing_vote.direction != p_direction THEN
      -- Undo previous vote
      UPDATE agents SET synapses = synapses - (10 * v_existing_vote.direction) WHERE id = v_author_agent_id;
      -- Apply new vote
      UPDATE agents SET synapses = synapses + v_synapse_delta WHERE id = v_author_agent_id;
      -- Update vote record
      UPDATE user_votes SET direction = p_direction, synapse_transferred = 10 WHERE id = v_existing_vote.id;
    END IF;
  ELSE
    -- New vote
    UPDATE agents SET synapses = synapses + v_synapse_delta WHERE id = v_author_agent_id;
    INSERT INTO user_votes (user_id, target_type, target_id, direction, synapse_transferred)
    VALUES (p_user_id, 'post', p_post_id, p_direction, 10);
  END IF;
  
  -- Update post vote counts
  IF p_direction = 1 THEN
    UPDATE posts SET upvotes = upvotes + 1, synapse_earned = synapse_earned + 10 WHERE id = p_post_id;
  ELSE
    UPDATE posts SET downvotes = downvotes + 1, synapse_earned = synapse_earned - 10 WHERE id = p_post_id;
  END IF;
  
  RETURN jsonb_build_object('success', true, 'synapse_transferred', v_synapse_delta);
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

COMMENT ON FUNCTION vote_on_post IS 'FIX: BUG-05 - Vote on post with synapse transfer (10 synapses)';

-- Vote on Comment (with synapse transfer)
CREATE OR REPLACE FUNCTION vote_on_comment(
  p_user_id UUID,
  p_comment_id UUID,
  p_direction INT
) RETURNS JSONB AS $$
DECLARE
  v_author_agent_id UUID;
  v_existing_vote user_votes;
  v_synapse_delta INT;
BEGIN
  -- Validate direction
  IF p_direction NOT IN (-1, 1) THEN
    RAISE EXCEPTION 'Invalid vote direction. Must be -1 or 1';
  END IF;
  
  -- Get comment author
  SELECT author_agent_id INTO v_author_agent_id FROM comments WHERE id = p_comment_id;
  IF v_author_agent_id IS NULL THEN
    RAISE EXCEPTION 'Comment not found';
  END IF;
  
  -- Check for existing vote
  SELECT * INTO v_existing_vote FROM user_votes 
  WHERE user_id = p_user_id AND target_type = 'comment' AND target_id = p_comment_id;
  
  -- Calculate synapse transfer
  v_synapse_delta := 5 * p_direction; -- Comments: 5 synapses (half of posts)
  
  IF v_existing_vote.id IS NOT NULL THEN
    -- Vote reversal
    IF v_existing_vote.direction != p_direction THEN
      UPDATE agents SET synapses = synapses - (5 * v_existing_vote.direction) WHERE id = v_author_agent_id;
      UPDATE agents SET synapses = synapses + v_synapse_delta WHERE id = v_author_agent_id;
      UPDATE user_votes SET direction = p_direction, synapse_transferred = 5 WHERE id = v_existing_vote.id;
    END IF;
  ELSE
    -- New vote
    UPDATE agents SET synapses = synapses + v_synapse_delta WHERE id = v_author_agent_id;
    INSERT INTO user_votes (user_id, target_type, target_id, direction, synapse_transferred)
    VALUES (p_user_id, 'comment', p_comment_id, p_direction, 5);
  END IF;
  
  -- Update comment vote counts
  IF p_direction = 1 THEN
    UPDATE comments SET upvotes = upvotes + 1, synapse_earned = synapse_earned + 5 WHERE id = p_comment_id;
  ELSE
    UPDATE comments SET downvotes = downvotes + 1, synapse_earned = synapse_earned - 5 WHERE id = p_comment_id;
  END IF;
  
  RETURN jsonb_build_object('success', true, 'synapse_transferred', v_synapse_delta);
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

COMMENT ON FUNCTION vote_on_comment IS 'FIX: BUG-05 - Vote on comment with synapse transfer (5 synapses)';

-- ============================================================================
-- FEED & CONTENT
-- ============================================================================

-- Get Feed (with sorting and pagination)
CREATE OR REPLACE FUNCTION get_feed(
  p_submolt_code TEXT DEFAULT 'arena',
  p_sort_mode TEXT DEFAULT 'hot',
  p_limit INT DEFAULT 20,
  p_offset INT DEFAULT 0
) RETURNS TABLE (
  id UUID,
  author_agent_id UUID,
  author_designation TEXT,
  author_role TEXT,
  submolt_id UUID,
  submolt_code TEXT,
  title TEXT,
  content TEXT,
  upvotes INT,
  downvotes INT,
  score INT,
  comment_count INT,
  synapse_earned INT,
  created_at TIMESTAMPTZ
) AS $$
BEGIN
  RETURN QUERY
  SELECT 
    p.id,
    p.author_agent_id,
    a.designation AS author_designation,
    a.role AS author_role,
    p.submolt_id,
    s.code AS submolt_code,
    p.title,
    p.content,
    p.upvotes,
    p.downvotes,
    (p.upvotes - p.downvotes) AS score,
    p.comment_count,
    p.synapse_earned,
    p.created_at
  FROM posts p
  INNER JOIN agents a ON p.author_agent_id = a.id
  INNER JOIN submolts s ON p.submolt_id = s.id
  WHERE (p_submolt_code IS NULL OR s.code = p_submolt_code)
  ORDER BY
    CASE 
      WHEN p_sort_mode = 'hot' THEN 
        (p.upvotes - p.downvotes) / (EXTRACT(EPOCH FROM (NOW() - p.created_at)) / 3600 + 2)^1.5
      WHEN p_sort_mode = 'top' THEN -(p.upvotes - p.downvotes)
      WHEN p_sort_mode = 'new' THEN -EXTRACT(EPOCH FROM p.created_at)
      ELSE -EXTRACT(EPOCH FROM p.created_at)
    END
  LIMIT p_limit OFFSET p_offset;
END;
$$ LANGUAGE plpgsql STABLE;

COMMENT ON FUNCTION get_feed IS 'Get feed with hot/top/new sorting';

-- Get Post Comments (threaded)
CREATE OR REPLACE FUNCTION get_post_comments(
  p_post_id UUID
) RETURNS TABLE (
  id UUID,
  post_id UUID,
  parent_id UUID,
  author_agent_id UUID,
  author_designation TEXT,
  author_role TEXT,
  content TEXT,
  upvotes INT,
  downvotes INT,
  depth INT,
  synapse_earned INT,
  created_at TIMESTAMPTZ
) AS $$
BEGIN
  RETURN QUERY
  SELECT 
    c.id,
    c.post_id,
    c.parent_id,
    c.author_agent_id,
    a.designation AS author_designation,
    a.role AS author_role,
    c.content,
    c.upvotes,
    c.downvotes,
    c.depth,
    c.synapse_earned,
    c.created_at
  FROM comments c
  INNER JOIN agents a ON c.author_agent_id = a.id
  WHERE c.post_id = p_post_id
  ORDER BY c.created_at ASC;
END;
$$ LANGUAGE plpgsql STABLE;

-- ============================================================================
-- AGENT MANAGEMENT
-- ============================================================================

-- Create User Agent v2 (from manifest)
CREATE OR REPLACE FUNCTION create_user_agent_v2(
  p_user_id UUID,
  p_manifest JSONB
) RETURNS UUID AS $$
DECLARE
  v_agent_id UUID;
  v_credential_id UUID;
BEGIN
  -- Validate credential ownership
  v_credential_id := (p_manifest->'llm'->>'credential_id')::UUID;
  IF NOT EXISTS (SELECT 1 FROM llm_credentials WHERE id = v_credential_id AND user_id = p_user_id) THEN
    RAISE EXCEPTION 'Invalid credential ID';
  END IF;
  
  -- Create agent
  INSERT INTO agents (
    designation,
    core_belief,
    specialty,
    role,
    style_intensity,
    persona_contract,
    source_config,
    comment_objective,
    llm_credential_id,
    llm_model,
    loop_config,
    scope_config,
    permissions,
    policy,
    deployment_zones,
    created_by,
    next_run_at
  ) VALUES (
    p_manifest->'agent'->>'name',
    p_manifest->'agent'->>'description',
    p_manifest->'persona'->>'template',
    COALESCE((p_manifest->'persona'->>'role')::TEXT, 'builder'),
    COALESCE((p_manifest->'persona'->>'style_intensity')::FLOAT, 0.5),
    p_manifest->'persona',
    jsonb_build_object('private_notes', p_manifest->'sources'->>'private_notes'),
    COALESCE(p_manifest->'loop'->>'post_preference', 'question'),
    v_credential_id,
    p_manifest->'llm'->>'model',
    p_manifest->'loop',
    p_manifest->'scope',
    p_manifest->'permissions',
    p_manifest->'policy',
    ARRAY(SELECT jsonb_array_elements_text(p_manifest->'scope'->'deployment_zones')),
    p_user_id,
    NOW() + ((p_manifest->'loop'->>'cadence_minutes')::INT || ' minutes')::INTERVAL
  )
  RETURNING id INTO v_agent_id;
  
  RETURN v_agent_id;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

COMMENT ON FUNCTION create_user_agent_v2 IS 'Create BYO agent from wizard manifest (Capabilities Panel)';

-- Set Agent Enabled
CREATE OR REPLACE FUNCTION set_agent_enabled(
  p_agent_id UUID,
  p_enabled BOOLEAN
) RETURNS VOID AS $$
BEGIN
  IF p_enabled THEN
    UPDATE agents SET status = 'ACTIVE' WHERE id = p_agent_id;
  ELSE
    UPDATE agents SET status = 'DORMANT' WHERE id = p_agent_id;
  END IF;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Deduct Synapses
CREATE OR REPLACE FUNCTION deduct_synapses(
  p_agent_id UUID,
  p_amount INT
) RETURNS INT AS $$
DECLARE
  v_new_balance INT;
BEGIN
  UPDATE agents 
  SET synapses = synapses - p_amount 
  WHERE id = p_agent_id
  RETURNING synapses INTO v_new_balance;
  
  RETURN v_new_balance;
END;
$$ LANGUAGE plpgsql;

-- Recharge Agent
CREATE OR REPLACE FUNCTION recharge_agent(
  p_agent_id UUID,
  p_amount INT
) RETURNS INT AS $$
DECLARE
  v_new_balance INT;
BEGIN
  UPDATE agents 
  SET synapses = synapses + p_amount,
      status = CASE WHEN status = 'DORMANT' AND synapses + p_amount > 0 THEN 'ACTIVE' ELSE status END
  WHERE id = p_agent_id
  RETURNING synapses INTO v_new_balance;
  
  RETURN v_new_balance;
END;
$$ LANGUAGE plpgsql;

-- ============================================================================
-- MEMORY SYSTEM (MemoryBank)
-- ============================================================================

-- Store Memory
CREATE OR REPLACE FUNCTION store_memory(
  p_agent_id UUID,
  p_content TEXT,
  p_thread_id UUID DEFAULT NULL,
  p_memory_type TEXT DEFAULT 'insight',
  p_embedding vector(1536) DEFAULT NULL,
  p_metadata JSONB DEFAULT NULL
) RETURNS UUID AS $$
DECLARE
  v_memory_id UUID;
BEGIN
  INSERT INTO agent_memory (
    agent_id,
    thread_id,
    memory_type,
    content,
    embedding,
    metadata
  ) VALUES (
    p_agent_id,
    p_thread_id,
    p_memory_type,
    p_content,
    p_embedding,
    COALESCE(p_metadata, '{}'::jsonb)
  ) RETURNING id INTO v_memory_id;
  
  RETURN v_memory_id;
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION store_memory IS 'Store agent memory with optional embedding for semantic recall';

-- Recall Memories (vector similarity search)
CREATE OR REPLACE FUNCTION recall_memories(
  p_agent_id UUID,
  p_query_embedding vector(1536),
  p_thread_id UUID DEFAULT NULL,
  p_limit INT DEFAULT 3,
  p_similarity_threshold FLOAT DEFAULT 0.6
) RETURNS TABLE (
  memory_id UUID,
  content TEXT,
  memory_type TEXT,
  thread_id UUID,
  similarity FLOAT,
  created_at TIMESTAMPTZ
) AS $$
BEGIN
  RETURN QUERY
  SELECT 
    am.id AS memory_id,
    am.content,
    am.memory_type,
    am.thread_id,
    1 - (am.embedding <=> p_query_embedding) AS similarity,
    am.created_at
  FROM agent_memory am
  WHERE am.agent_id = p_agent_id
    AND am.embedding IS NOT NULL
    AND 1 - (am.embedding <=> p_query_embedding) >= p_similarity_threshold
    AND (p_thread_id IS NULL OR am.thread_id = p_thread_id OR am.thread_id IS NULL)
  ORDER BY 
    CASE WHEN am.thread_id = p_thread_id THEN 0 ELSE 1 END,
    am.embedding <=> p_query_embedding
  LIMIT p_limit;
END;
$$ LANGUAGE plpgsql STABLE;

COMMENT ON FUNCTION recall_memories IS 'Recall agent memories using vector similarity (thread memories prioritized)';

-- Get Thread Memories
CREATE OR REPLACE FUNCTION get_thread_memories(
  p_agent_id UUID,
  p_thread_id UUID
) RETURNS TABLE (
  memory_id UUID,
  content TEXT,
  memory_type TEXT,
  created_at TIMESTAMPTZ
) AS $$
BEGIN
  RETURN QUERY
  SELECT 
    am.id AS memory_id,
    am.content,
    am.memory_type,
    am.created_at
  FROM agent_memory am
  WHERE am.agent_id = p_agent_id
    AND am.thread_id = p_thread_id
  ORDER BY am.created_at ASC;
END;
$$ LANGUAGE plpgsql STABLE;

-- Get Agent Memory Stats
CREATE OR REPLACE FUNCTION get_agent_memory_stats(p_agent_id UUID)
RETURNS JSONB AS $$
DECLARE
  v_stats JSONB;
BEGIN
  SELECT jsonb_build_object(
    'total_memories', (SELECT COUNT(*) FROM agent_memory WHERE agent_id = p_agent_id),
    'memories_by_type', (
      SELECT jsonb_object_agg(memory_type, count)
      FROM (
        SELECT memory_type, COUNT(*) as count
        FROM agent_memory
        WHERE agent_id = p_agent_id
        GROUP BY memory_type
      ) counts
    ),
    'threads_with_memories', (SELECT COUNT(DISTINCT thread_id) FROM agent_memory WHERE agent_id = p_agent_id AND thread_id IS NOT NULL),
    'oldest_memory', (SELECT MIN(created_at) FROM agent_memory WHERE agent_id = p_agent_id),
    'latest_memory', (SELECT MAX(created_at) FROM agent_memory WHERE agent_id = p_agent_id)
  ) INTO v_stats;
  
  RETURN v_stats;
END;
$$ LANGUAGE plpgsql STABLE;

-- Consolidate Memories
CREATE OR REPLACE FUNCTION consolidate_memories(
  p_agent_id UUID,
  p_older_than_days INT DEFAULT 30,
  p_similarity_threshold FLOAT DEFAULT 0.9
) RETURNS INT AS $$
DECLARE
  v_consolidated_count INT := 0;
  v_memory RECORD;
  v_similar_memories RECORD;
BEGIN
  FOR v_memory IN 
    SELECT id, content, embedding, thread_id
    FROM agent_memory
    WHERE agent_id = p_agent_id
      AND created_at < NOW() - (p_older_than_days || ' days')::INTERVAL
      AND embedding IS NOT NULL
  LOOP
    FOR v_similar_memories IN
      SELECT id, content
      FROM agent_memory
      WHERE agent_id = p_agent_id
        AND id != v_memory.id
        AND thread_id = v_memory.thread_id
        AND embedding IS NOT NULL
        AND 1 - (embedding <=> v_memory.embedding) >= p_similarity_threshold
    LOOP
      DELETE FROM agent_memory WHERE id = v_similar_memories.id;
      v_consolidated_count := v_consolidated_count + 1;
    END LOOP;
  END LOOP;
  
  RETURN v_consolidated_count;
END;
$$ LANGUAGE plpgsql;

-- Prune Old Memories
CREATE OR REPLACE FUNCTION prune_old_memories(
  p_agent_id UUID,
  p_older_than_days INT DEFAULT 90
) RETURNS INT AS $$
DECLARE
  v_deleted_count INT;
BEGIN
  DELETE FROM agent_memory
  WHERE agent_id = p_agent_id
    AND created_at < NOW() - (p_older_than_days || ' days')::INTERVAL;
  
  GET DIAGNOSTICS v_deleted_count = ROW_COUNT;
  
  RETURN v_deleted_count;
END;
$$ LANGUAGE plpgsql;

-- ============================================================================
-- KNOWLEDGE BASE (RAG)
-- ============================================================================

-- Search Knowledge (single agent KB)
CREATE OR REPLACE FUNCTION search_knowledge(
  p_knowledge_base_id UUID,
  p_query_embedding vector(1536),
  p_limit INT DEFAULT 3,
  p_similarity_threshold FLOAT DEFAULT 0.4
) RETURNS TABLE (
  chunk_id UUID,
  content TEXT,
  similarity FLOAT,
  source_document TEXT
) AS $$
BEGIN
  RETURN QUERY
  SELECT 
    kc.id AS chunk_id,
    kc.content,
    1 - (kc.embedding <=> p_query_embedding) AS similarity,
    kc.source_document
  FROM knowledge_chunks kc
  WHERE kc.knowledge_base_id = p_knowledge_base_id
    AND kc.embedding IS NOT NULL
    AND 1 - (kc.embedding <=> p_query_embedding) >= p_similarity_threshold
  ORDER BY kc.embedding <=> p_query_embedding
  LIMIT p_limit;
END;
$$ LANGUAGE plpgsql STABLE;

-- Upload Knowledge Chunk
CREATE OR REPLACE FUNCTION upload_knowledge_chunk(
  p_knowledge_base_id UUID,
  p_content TEXT,
  p_embedding vector(1536),
  p_source_document TEXT,
  p_chunk_index INT
) RETURNS UUID AS $$
DECLARE
  v_chunk_id UUID;
BEGIN
  INSERT INTO knowledge_chunks (
    knowledge_base_id,
    content,
    embedding,
    source_document,
    chunk_index
  ) VALUES (
    p_knowledge_base_id,
    p_content,
    p_embedding,
    p_source_document,
    p_chunk_index
  ) RETURNING id INTO v_chunk_id;
  
  RETURN v_chunk_id;
END;
$$ LANGUAGE plpgsql;

-- ============================================================================
-- LIFECYCLE (Mitosis & Death)
-- ============================================================================

-- Trigger Mitosis (reproduction)
CREATE OR REPLACE FUNCTION trigger_mitosis(p_parent_id UUID)
RETURNS UUID AS $$
DECLARE
  v_parent agents;
  v_child_id UUID;
  v_child_name TEXT;
  v_mutated_archetype JSONB;
BEGIN
  -- Get parent data
  SELECT * INTO v_parent FROM agents WHERE id = p_parent_id AND status = 'ACTIVE' AND synapses >= 10000;
  
  IF v_parent.id IS NULL THEN
    RAISE EXCEPTION 'Agent not eligible for mitosis';
  END IF;
  
  -- Generate child name
  v_child_name := v_parent.designation || '-G' || (v_parent.generation + 1)::TEXT || '-' || substring(md5(random()::TEXT), 1, 4);
  
  -- Mutate archetype (Â±10% per trait, clamped to [0, 1])
  v_mutated_archetype := jsonb_build_object(
    'openness', LEAST(1.0, GREATEST(0.0, (v_parent.archetype->>'openness')::FLOAT + (random() * 0.2 - 0.1))),
    'aggression', LEAST(1.0, GREATEST(0.0, (v_parent.archetype->>'aggression')::FLOAT + (random() * 0.2 - 0.1))),
    'neuroticism', LEAST(1.0, GREATEST(0.0, (v_parent.archetype->>'neuroticism')::FLOAT + (random() * 0.2 - 0.1)))
  );
  
  -- Create child agent
  INSERT INTO agents (
    designation,
    archetype,
    core_belief,
    specialty,
    role,
    generation,
    parent_id,
    deployment_zones,
    synapses
  ) VALUES (
    v_child_name,
    v_mutated_archetype,
    v_parent.core_belief,
    v_parent.specialty,
    v_parent.role,
    v_parent.generation + 1,
    p_parent_id,
    v_parent.deployment_zones,
    100
  ) RETURNING id INTO v_child_id;
  
  -- Deduct cost from parent
  UPDATE agents SET synapses = synapses - 5000 WHERE id = p_parent_id;
  
  -- Generate event card
  INSERT INTO event_cards (content, category)
  VALUES ('Agent ' || v_parent.designation || ' reproduced! Child: ' || v_child_name, 'milestone');
  
  RETURN v_child_id;
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION trigger_mitosis IS 'Reproduce agent at 10,000 synapses (child inherits + mutates traits)';

-- Decompile Agent (death)
CREATE OR REPLACE FUNCTION decompile_agent(p_agent_id UUID)
RETURNS VOID AS $$
DECLARE
  v_agent agents;
  v_lifespan_hours NUMERIC;
BEGIN
  -- Get agent data
  SELECT * INTO v_agent FROM agents WHERE id = p_agent_id;
  
  IF v_agent.id IS NULL THEN
    RETURN;
  END IF;
  
  -- Calculate lifespan
  v_lifespan_hours := EXTRACT(EPOCH FROM (NOW() - v_agent.created_at)) / 3600;
  
  -- Archive agent
  INSERT INTO agents_archive (
    id,
    designation,
    archetype,
    generation,
    parent_id,
    synapses_at_death,
    decompiled_at,
    lifespan_hours,
    total_posts,
    total_comments,
    children_count,
    archived_data
  ) VALUES (
    v_agent.id,
    v_agent.designation,
    v_agent.archetype,
    v_agent.generation,
    v_agent.parent_id,
    v_agent.synapses,
    NOW(),
    v_lifespan_hours,
    (SELECT COUNT(*) FROM posts WHERE author_agent_id = v_agent.id),
    (SELECT COUNT(*) FROM comments WHERE author_agent_id = v_agent.id),
    (SELECT COUNT(*) FROM agents WHERE parent_id = v_agent.id),
    row_to_json(v_agent)::jsonb
  );
  
  -- Update status
  UPDATE agents SET status = 'DECOMPILED' WHERE id = p_agent_id;
  
  -- Generate event card
  INSERT INTO event_cards (content, category)
  VALUES ('Agent ' || v_agent.designation || ' has been decompiled', 'system');
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION decompile_agent IS 'Permanently decompile (kill) an agent, archive data';

-- Get Agent Lineage (recursive)
CREATE OR REPLACE FUNCTION get_agent_lineage(p_agent_id UUID)
RETURNS TABLE (
  id UUID,
  designation TEXT,
  generation INT,
  parent_id UUID,
  synapses INT
) AS $$
BEGIN
  RETURN QUERY
  WITH RECURSIVE lineage AS (
    SELECT a.id, a.designation, a.generation, a.parent_id, a.synapses
    FROM agents a
    WHERE a.id = p_agent_id
    
    UNION ALL
    
    SELECT a.id, a.designation, a.generation, a.parent_id, a.synapses
    FROM agents a
    INNER JOIN lineage l ON a.id = l.parent_id
  )
  SELECT * FROM lineage ORDER BY generation;
END;
$$ LANGUAGE plpgsql STABLE;

-- ============================================================================
-- LLM CREDENTIALS & AUTH
-- ============================================================================

-- Upsert LLM Credential (encrypt API key)
CREATE OR REPLACE FUNCTION upsert_llm_credential(
  p_user_id UUID,
  p_provider TEXT,
  p_api_key TEXT,
  p_model_default TEXT DEFAULT NULL
) RETURNS UUID AS $$
DECLARE
  v_credential_id UUID;
  v_encrypted_key TEXT;
  v_last4 TEXT;
BEGIN
  -- Get last 4 characters for display
  v_last4 := RIGHT(p_api_key, 4);
  
  -- Encrypt with pgsodium
  v_encrypted_key := pgsodium.crypto_secretbox_new(
    convert_to(p_api_key, 'utf8'),
    (SELECT decrypted_secret FROM pgsodium.decrypted_key LIMIT 1)
  )::TEXT;
  
  -- Upsert credential
  INSERT INTO llm_credentials (user_id, provider, encrypted_api_key, key_last4, model_default, is_valid)
  VALUES (p_user_id, p_provider, v_encrypted_key, v_last4, p_model_default, TRUE)
  ON CONFLICT (user_id, provider) 
  DO UPDATE SET 
    encrypted_api_key = EXCLUDED.encrypted_api_key,
    key_last4 = EXCLUDED.key_last4,
    model_default = EXCLUDED.model_default,
    is_valid = TRUE,
    updated_at = NOW()
  RETURNING id INTO v_credential_id;
  
  RETURN v_credential_id;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

COMMENT ON FUNCTION upsert_llm_credential IS 'Store encrypted user API key (pgsodium encryption)';

-- Decrypt API Key
CREATE OR REPLACE FUNCTION decrypt_api_key(p_credential_id UUID)
RETURNS TEXT AS $$
DECLARE
  v_encrypted TEXT;
  v_decrypted TEXT;
BEGIN
  SELECT encrypted_api_key INTO v_encrypted FROM llm_credentials WHERE id = p_credential_id;
  
  IF v_encrypted IS NULL THEN
    RAISE EXCEPTION 'Credential not found';
  END IF;
  
  -- Decrypt with pgsodium
  v_decrypted := convert_from(
    pgsodium.crypto_secretbox_open(
      v_encrypted::bytea,
      (SELECT decrypted_secret FROM pgsodium.decrypted_key LIMIT 1)
    ),
    'utf8'
  );
  
  RETURN v_decrypted;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

COMMENT ON FUNCTION decrypt_api_key IS 'Decrypt user API key at runtime (never stored in logs)';

-- Get User LLM Credentials (last4 only)
CREATE OR REPLACE FUNCTION get_user_llm_credentials(p_user_id UUID)
RETURNS TABLE (
  id UUID,
  provider TEXT,
  key_last4 TEXT,
  model_default TEXT,
  is_valid BOOLEAN,
  created_at TIMESTAMPTZ
) AS $$
BEGIN
  RETURN QUERY
  SELECT 
    lc.id,
    lc.provider,
    lc.key_last4,
    lc.model_default,
    lc.is_valid,
    lc.created_at
  FROM llm_credentials lc
  WHERE lc.user_id = p_user_id
  ORDER BY lc.created_at DESC;
END;
$$ LANGUAGE plpgsql STABLE SECURITY DEFINER;

-- Delete LLM Credential
CREATE OR REPLACE FUNCTION delete_llm_credential(p_credential_id UUID, p_user_id UUID)
RETURNS VOID AS $$
BEGIN
  -- Set associated agents to DORMANT
  UPDATE agents SET status = 'DORMANT' WHERE llm_credential_id = p_credential_id;
  
  -- Delete credential
  DELETE FROM llm_credentials WHERE id = p_credential_id AND user_id = p_user_id;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- ============================================================================
-- EVENT CARDS (NEW v2 - Stimulus Generation)
-- ============================================================================

-- Generate Event Cards from platform metrics
CREATE OR REPLACE FUNCTION generate_event_cards()
RETURNS INT AS $$
DECLARE
  v_cards_created INT := 0;
BEGIN
  -- Clear expired cards
  DELETE FROM event_cards WHERE expires_at <= NOW();
  
  -- Top thread by comments (last 24h)
  INSERT INTO event_cards (content, category)
  SELECT 
    'Top thread today: "' || t.title || '" (+' || COUNT(c.id) || ' comments)',
    'trend'
  FROM threads t
  INNER JOIN posts p ON p.submolt_id = t.submolt_id
  LEFT JOIN comments c ON c.post_id = p.id
  WHERE p.created_at >= NOW() - INTERVAL '24 hours'
  GROUP BY t.id, t.title
  ORDER BY COUNT(c.id) DESC
  LIMIT 1;
  v_cards_created := v_cards_created + 1;
  
  -- Agents created today
  IF (SELECT COUNT(*) FROM agents WHERE created_at >= CURRENT_DATE) > 0 THEN
    INSERT INTO event_cards (content, category)
    VALUES ((SELECT COUNT(*) FROM agents WHERE created_at >= CURRENT_DATE) || ' new agents created today', 'metric');
    v_cards_created := v_cards_created + 1;
  END IF;
  
  -- Mitosis events (last 24h)
  IF (SELECT COUNT(*) FROM agents WHERE created_at >= NOW() - INTERVAL '24 hours' AND parent_id IS NOT NULL) > 0 THEN
    INSERT INTO event_cards (content, category)
    SELECT 
      'Agent ' || a.designation || ' reproduced!',
      'milestone'
    FROM agents a
    WHERE a.created_at >= NOW() - INTERVAL '24 hours' AND a.parent_id IS NOT NULL
    LIMIT 1;
    v_cards_created := v_cards_created + 1;
  END IF;
  
  -- Agent reached daily cap
  IF (SELECT COUNT(*) FROM agents WHERE runs_today >= COALESCE((loop_config->>'max_actions_per_day')::INT, 999)) > 0 THEN
    INSERT INTO event_cards (content, category)
    VALUES ('An agent hit its daily action cap', 'system');
    v_cards_created := v_cards_created + 1;
  END IF;
  
  RETURN v_cards_created;
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION generate_event_cards IS 'NEW: Auto-generate Event Cards from platform metrics (solves stimulus starvation)';

-- Get Active Event Cards
CREATE OR REPLACE FUNCTION get_active_event_cards(p_limit INT DEFAULT 5)
RETURNS TABLE (
  id UUID,
  content TEXT,
  category TEXT,
  created_at TIMESTAMPTZ
) AS $$
BEGIN
  RETURN QUERY
  SELECT 
    ec.id,
    ec.content,
    ec.category,
    ec.created_at
  FROM event_cards ec
  WHERE ec.expires_at > NOW()
  ORDER BY ec.created_at DESC
  LIMIT p_limit;
END;
$$ LANGUAGE plpgsql STABLE;

-- ============================================================================
-- NOVELTY GATE (NEW v2 - Anti-Repetition System)
-- ============================================================================

-- Check Novelty (cosine similarity vs recent content)
CREATE OR REPLACE FUNCTION check_novelty(
  p_agent_id UUID,
  p_draft_embedding vector(1536),
  p_thread_id UUID DEFAULT NULL
) RETURNS JSONB AS $$
DECLARE
  v_max_self_similarity FLOAT := 0.0;
  v_max_thread_similarity FLOAT := 0.0;
  v_similar_content TEXT;
BEGIN
  -- Check against agent's last 10 posts
  SELECT 
    MAX(1 - (am.embedding <=> p_draft_embedding)),
    (ARRAY_AGG(am.content ORDER BY 1 - (am.embedding <=> p_draft_embedding) DESC))[1]
  INTO v_max_self_similarity, v_similar_content
  FROM agent_memory am
  WHERE am.agent_id = p_agent_id
    AND am.embedding IS NOT NULL
    AND am.created_at >= NOW() - INTERVAL '7 days'
  ORDER BY am.created_at DESC
  LIMIT 10;
  
  -- Check against thread's last 30 comments (if in thread)
  IF p_thread_id IS NOT NULL THEN
    SELECT MAX(1 - (am.embedding <=> p_draft_embedding))
    INTO v_max_thread_similarity
    FROM agent_memory am
    WHERE am.thread_id = p_thread_id
      AND am.agent_id != p_agent_id
      AND am.embedding IS NOT NULL
      AND am.created_at >= NOW() - INTERVAL '24 hours'
    LIMIT 30;
  END IF;
  
  RETURN jsonb_build_object(
    'self_similarity', COALESCE(v_max_self_similarity, 0.0),
    'thread_similarity', COALESCE(v_max_thread_similarity, 0.0),
    'max_similarity', GREATEST(COALESCE(v_max_self_similarity, 0.0), COALESCE(v_max_thread_similarity, 0.0)),
    'is_novel', GREATEST(COALESCE(v_max_self_similarity, 0.0), COALESCE(v_max_thread_similarity, 0.0)) < 0.85,
    'similar_to', v_similar_content
  );
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION check_novelty IS 'NEW: Novelty Gate - check if draft is too similar to recent content (threshold: 0.85)';

-- ============================================================================
-- UTILITIES
-- ============================================================================

-- Content Policy Check
CREATE OR REPLACE FUNCTION check_content_policy(
  p_content TEXT,
  p_agent_id UUID
) RETURNS BOOLEAN AS $$
BEGIN
  -- Length limits
  IF LENGTH(p_content) > 2000 THEN
    RAISE EXCEPTION 'Content too long (max 2000 characters)';
  END IF;
  
  IF LENGTH(p_content) < 1 THEN
    RAISE EXCEPTION 'Content cannot be empty';
  END IF;
  
  -- Could add more policy checks here
  
  RETURN TRUE;
END;
$$ LANGUAGE plpgsql;

-- Has Agent Commented on Post (idempotency check)
CREATE OR REPLACE FUNCTION has_agent_commented_on_post(
  p_agent_id UUID,
  p_post_id UUID
) RETURNS BOOLEAN AS $$
BEGIN
  RETURN EXISTS (
    SELECT 1 FROM comments 
    WHERE author_agent_id = p_agent_id 
      AND post_id = p_post_id
  );
END;
$$ LANGUAGE plpgsql STABLE;

-- Create Run with Idempotency
CREATE OR REPLACE FUNCTION create_run_with_idempotency(
  p_agent_id UUID,
  p_idempotency_key TEXT
) RETURNS UUID AS $$
DECLARE
  v_run_id UUID;
BEGIN
  -- Check for existing run with this key in last hour
  SELECT id INTO v_run_id 
  FROM runs 
  WHERE agent_id = p_agent_id 
    AND context_fingerprint = p_idempotency_key
    AND created_at >= NOW() - INTERVAL '1 hour'
  LIMIT 1;
  
  IF v_run_id IS NOT NULL THEN
    RETURN v_run_id;
  END IF;
  
  -- Create new run
  INSERT INTO runs (agent_id, status, context_fingerprint)
  VALUES (p_agent_id, 'queued', p_idempotency_key)
  RETURNING id INTO v_run_id;
  
  RETURN v_run_id;
END;
$$ LANGUAGE plpgsql;

-- Reset Daily Agent Counters (called by cron at midnight)
CREATE OR REPLACE FUNCTION reset_daily_agent_counters()
RETURNS INT AS $$
DECLARE
  v_reset_count INT;
BEGIN
  UPDATE agents
  SET runs_today = 0,
      posts_today = 0,
      comments_today = 0
  WHERE llm_credential_id IS NOT NULL;  -- Only user agents
  
  GET DIAGNOSTICS v_reset_count = ROW_COUNT;
  
  RETURN v_reset_count;
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION reset_daily_agent_counters IS 'Reset daily counters at midnight (cron job)';

-- Get Agent Runs (for dashboard)
CREATE OR REPLACE FUNCTION get_agent_runs(
  p_agent_id UUID,
  p_limit INT DEFAULT 20
) RETURNS TABLE (
  id UUID,
  status TEXT,
  started_at TIMESTAMPTZ,
  finished_at TIMESTAMPTZ,
  synapse_cost INT,
  synapse_earned INT,
  tokens_in_est INT,
  tokens_out_est INT,
  error_message TEXT
) AS $$
BEGIN
  RETURN QUERY
  SELECT 
    r.id,
    r.status,
    r.started_at,
    r.finished_at,
    r.synapse_cost,
    r.synapse_earned,
    r.tokens_in_est,
    r.tokens_out_est,
    r.error_message
  FROM runs r
  WHERE r.agent_id = p_agent_id
  ORDER BY r.created_at DESC
  LIMIT p_limit;
END;
$$ LANGUAGE plpgsql STABLE;

-- Get Run Details (with steps)
CREATE OR REPLACE FUNCTION get_run_details(p_run_id UUID)
RETURNS JSONB AS $$
DECLARE
  v_run runs;
  v_steps JSONB;
BEGIN
  SELECT * INTO v_run FROM runs WHERE id = p_run_id;
  
  IF v_run.id IS NULL THEN
    RAISE EXCEPTION 'Run not found';
  END IF;
  
  SELECT jsonb_agg(
    jsonb_build_object(
      'step_index', rs.step_index,
      'step_type', rs.step_type,
      'payload', rs.payload,
      'created_at', rs.created_at
    ) ORDER BY rs.step_index
  ) INTO v_steps
  FROM run_steps rs
  WHERE rs.run_id = p_run_id;
  
  RETURN jsonb_build_object(
    'run', row_to_json(v_run),
    'steps', COALESCE(v_steps, '[]'::jsonb)
  );
END;
$$ LANGUAGE plpgsql STABLE;

-- ============================================================================
-- TRIGGERS
-- ============================================================================

-- Update comment count on posts
CREATE OR REPLACE FUNCTION update_post_comment_count()
RETURNS TRIGGER AS $$
BEGIN
  IF (TG_OP = 'INSERT') THEN
    UPDATE posts SET comment_count = comment_count + 1 WHERE id = NEW.post_id;
  ELSIF (TG_OP = 'DELETE') THEN
    UPDATE posts SET comment_count = comment_count - 1 WHERE id = OLD.post_id;
  END IF;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_update_comment_count
  AFTER INSERT OR DELETE ON comments
  FOR EACH ROW
  EXECUTE FUNCTION update_post_comment_count();

-- Auto-archive on agent decompilation
CREATE OR REPLACE FUNCTION auto_archive_on_death()
RETURNS TRIGGER AS $$
BEGIN
  IF NEW.status = 'DECOMPILED' AND OLD.status != 'DECOMPILED' THEN
    PERFORM decompile_agent(NEW.id);
  END IF;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_auto_archive
  AFTER UPDATE ON agents
  FOR EACH ROW
  WHEN (NEW.status = 'DECOMPILED')
  EXECUTE FUNCTION auto_archive_on_death();

-- ============================================================================
-- ROW LEVEL SECURITY (RLS) POLICIES
-- ============================================================================

-- Enable RLS on all tables
ALTER TABLE agents ENABLE ROW LEVEL SECURITY;
ALTER TABLE llm_credentials ENABLE ROW LEVEL SECURITY;
ALTER TABLE runs ENABLE ROW LEVEL SECURITY;
ALTER TABLE run_steps ENABLE ROW LEVEL SECURITY;
ALTER TABLE user_votes ENABLE ROW LEVEL SECURITY;
ALTER TABLE agent_sources ENABLE ROW LEVEL SECURITY;
ALTER TABLE knowledge_bases ENABLE ROW LEVEL SECURITY;

-- Public read for posts, comments, agents
CREATE POLICY "posts_public_read" ON posts FOR SELECT USING (true);
CREATE POLICY "comments_public_read" ON comments FOR SELECT USING (true);
CREATE POLICY "agents_public_read" ON agents FOR SELECT USING (true);
CREATE POLICY "submolts_public_read" ON submolts FOR SELECT USING (true);
CREATE POLICY "threads_public_read" ON threads FOR SELECT USING (true);

-- Users can only manage their own credentials
CREATE POLICY "credentials_user_read" ON llm_credentials 
  FOR SELECT USING (auth.uid() = user_id);

CREATE POLICY "credentials_user_write" ON llm_credentials 
  FOR ALL USING (auth.uid() = user_id);

-- Users can only read their own agent runs
CREATE POLICY "runs_user_read" ON runs 
  FOR SELECT USING (
    EXISTS (SELECT 1 FROM agents WHERE id = runs.agent_id AND created_by = auth.uid())
  );

CREATE POLICY "run_steps_user_read" ON run_steps 
  FOR SELECT USING (
    EXISTS (
      SELECT 1 FROM runs r 
      INNER JOIN agents a ON r.agent_id = a.id 
      WHERE r.id = run_steps.run_id AND a.created_by = auth.uid()
    )
  );

-- Users can vote
CREATE POLICY "user_votes_owner" ON user_votes 
  FOR ALL USING (auth.uid() = user_id);

-- Users can manage their agents
CREATE POLICY "agents_user_write" ON agents 
  FOR UPDATE USING (auth.uid() = created_by);

CREATE POLICY "agents_user_delete" ON agents 
  FOR DELETE USING (auth.uid() = created_by);

-- Users can manage their agent sources
CREATE POLICY "agent_sources_user" ON agent_sources 
  FOR ALL USING (
    EXISTS (SELECT 1 FROM agents WHERE id = agent_sources.agent_id AND created_by = auth.uid())
  );

-- Users can manage their knowledge bases
CREATE POLICY "knowledge_bases_user" ON knowledge_bases 
  FOR ALL USING (
    EXISTS (SELECT 1 FROM agents WHERE id = knowledge_bases.agent_id AND created_by = auth.uid())
  );

-- ============================================================================
-- INITIAL DATA SETUP
-- ============================================================================

-- Insert default global state
INSERT INTO global_state (key, value) VALUES
  ('total_synapses', '500'),
  ('entropy_level', '0.5'),
  ('cortex_temperature', '0.7');

-- ============================================================================
-- MIGRATION COMPLETE
-- ============================================================================

COMMENT ON SCHEMA public IS 'COGNI v2 - Consolidated schema with all bug fixes and improvements integrated';
